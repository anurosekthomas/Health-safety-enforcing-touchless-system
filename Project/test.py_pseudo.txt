from itertools IMPORT count

from tensorflow.keras.applications.mobilenet_v2 IMPORT preprocess_INPUT

from tensorflow.keras.preprocessing.image IMPORT img_to_array

from tensorflow.keras.models IMPORT load_model

from imutils.video IMPORT VideoStream

IMPORT speech_recognition as spr

from playsound IMPORT playsound

IMPORT threading

from tkinter IMPORT *

IMPORT tkinter as tki

from PIL IMPORT Image as Img

from PIL IMPORT ImageTk

IMPORT numpy as np

IMPORT imutils

IMPORT os

IMPORT cv2

IMPORT time

IMPORT sqlite3

from datetime IMPORT datetime



SET counter_no_mask TO 0

SET counter TO 0



#load our serialized face detector model from disk

SET prototxtPath TO r"face_detector\deploy.prototxt"

SET weightsPath TO r"face_detector\res10_300x300_ssd_iter_140000.caffemodel"

SET faceNet TO cv2.dnn.readNet(prototxtPath, weightsPath)



# load the face mask detector model from disk

SET maskNet TO load_model("mask_detector.model")



# initialize the video stream

SET vs TO VideoStream(src=0).start()



DEFINE CLASS SpeechRecognizer(threading.Thread):

    

    DEFINE FUNCTION __init__(self):

        super(SpeechRecognizer, self).__init__()

        self.setDaemon(True)

        SET self.question_text TO ""

        SET self.answer_text TO ""

        SET self.start_face_detection TO False

        SET self.delay TO 0



       

    

    DEFINE FUNCTION check_in_database(self, collected_data):

        SET name TO '%' + collected_data[0] + '%'

        SET phone TO collected_data[3].replace(' ', '')



         # sqllite connection.

        SET govt_database_file TO "GovtData.db"

        SET conn TO sqlite3.connect(govt_database_file)

        SET db_cursor TO conn.cursor()

        db_cursor.execute(

            "SELECT 1 FROM Person WHERE Name LIKE '{}' AND Phone LIKE '{}'".format(name, phone))

        SET query_result TO db_cursor.fetchall()

        IF len(query_result) > 0:

            RETURN 1

        RETURN 0



    DEFINE FUNCTION save_to_db(self,collected_data):

        SET name  TO collected_data[0]

        SET place TO collected_data[1]

        SET is_vaccinated TO 0

        IF (collected_data[2]=="yes"):

            SET is_vaccinated TO 1

        SET phone TO collected_data[3].replace(' ', '')

        SET today TO datetime.now()



        # sqllite connection.

        SET customer_db TO "customer.db"

        SET conn TO sqlite3.connect(customer_db)

        SET db_cursor TO conn.cursor()

        db_cursor.execute("INSERT INTO Customer (Name, Place, Phone, IsVaccinated, VisitTime) VALUES ('{}','{}','{}','{}','{}')".format(name, place, phone, is_vaccinated, today))

        conn.commit()

        conn.close()







    DEFINE FUNCTION run(self):

        WHILE True:

            IF self.start_face_detection EQUALS False:

                IF self.delay==1:

                    SET self.question_text TO "You are Welcome"

                    time.sleep(3)

                    self.delay=0

                SET recognition TO spr.Recognizer()

                SET mc TO spr.Microphone(device_index=0)



                SET collected_data TO ["", "", "", ""]

                SET self.question_text TO "Say Hello to start"

                playsound("hello.mp3")

                WHILE True:

                    with mc as source:

                        TRY:

                            SET audio TO recognition.listen(source)

                            SET rec_text TO recognition.recognize_google(audio).lower()

                        EXCEPT:

                            continue

                        IF (rec_text.find('hello') > -1):

                            SET self.answer_text TO 'Your Answer: ' + "Hello"

                            time.sleep(2)

                            SET self.answer_text TO ""

                            break



                SET questions TO ["What is your name: ","Where are you from: ","Have you been vaccinated: ","What is your phone number: "]

                SET audios TO ["name.mp3","place.mp3","vaccination.mp3","phone.mp3"]



                with mc as source:

                    FOR i IN range (0, 4):

                        SET self.question_text TO questions[i]

                        playsound(audios[i])

                        SET text TO ""

                        while(text==""):

                            TRY:

                                SET audio TO recognition.listen(source)

                                SET text TO recognition.recognize_google(audio)

                                

                                # Adding collected data into list.

                                SET collected_data[i] TO text 

                                SET self.answer_text TO 'Your Answer: ' + text

                            EXCEPT:

                                OUTPUT("Please Tell Something")

                        time.sleep(3)

                        SET self.answer_text TO ""

                self.save_to_db(collected_data)

                if(self.check_in_database(collected_data) EQUALS 1):

                    SET self.question_text TO "You were recommended to be at quarantine"

                    playsound('alert.mp3')

                    time.sleep(3)

                ELSE:

                    SET self.question_text TO "Please wait UNTIL we detect your mask properly."

                    time.sleep(3)

                    SET self.start_face_detection TO True

                

            ELSE:

                time.sleep(1)



            





SET recognizer TO SpeechRecognizer()

recognizer.start()



DEFINE CLASS App(object):



    DEFINE FUNCTION __init__(self,root):

        SET self.root TO root

        self.root.geometry('700x600')

        self.root.title('Covid Demo')

        SET self.num TO 1

        SET self.start_face_detection TO False





        # Question label.

        SET self.question_label TO tki.Label(self.root, text="",bd='10',fg TO "black",bg TO "orange",width=60, height=2,font TO "Helvetica 16 bold")

        self.question_label.pack(side=TOP) # Center alligned

        # self.question_label.configure(text="Your Answer: {}".format("Nirmal"))



        # Answer label.

        SET self.answer_label TO tki.Label(self.root, text="",bd='10',fg TO "black",bg TO "cyan",width=60, height=2,font TO "Helvetica 16 bold")

        self.answer_label.pack(side=TOP) # Center alligned

        # self.answer_label.configure(text="Your Answer: {}".format("Nirmal"))



        



        # Create a label IN the frame

        SET self.lmain TO tki.Label(self.root)

        self.lmain.pack()



        # Show camera function.

        self.video_stream()

        

    DEFINE FUNCTION detect_and_predict_mask(self,frame, faceNet, maskNet):

        # grab the dimensions of the frame and then construct a blob

        # from it

        SET (h, w) TO frame.shape[:2]

        SET blob TO cv2.dnn.blobFromImage(frame, 1.0, (224, 224),

            (104.0, 177.0, 123.0))



        # PASS the blob through the network and obtain the face detections

        faceNet.setInput(blob)

        SET detections TO faceNet.forward()

        # OUTPUT(detections.shape)



        # initialize our list of faces, their corresponding locations,

        # and the list of predictions from our face mask network

        SET faces TO []

        SET locs TO []

        SET preds TO []



        # loop over the detections

        FOR i IN range(0, detections.shape[2]):

            # extract the confidence (i.e., probability) associated with

            # the detection

            SET confidence TO detections[0, 0, i, 2]



            # filter out weak detections by ensuring the confidence is

            # greater than the minimum confidence

            IF confidence > 0.5:

                # compute the (x, y)-coordinates of the bounding box FOR

                # the object

                SET box TO detections[0, 0, i, 3:7] * np.array([w, h, w, h])

                SET (startX, startY, endX, endY) TO box.astype("int")



                # ensure the bounding boxes fall within the dimensions of

                # the frame

                SET (startX, startY) TO (max(0, startX), max(0, startY))

                SET (endX, endY) TO (min(w - 1, endX), min(h - 1, endY))



                # extract the face ROI, convert it from BGR to RGB channel

                # ordering, resize it to 224x224, and preprocess it

                SET face TO frame[startY:endY, startX:endX]

                SET face TO cv2.cvtColor(face, cv2.COLOR_BGR2RGB)

                SET face TO cv2.resize(face, (224, 224))

                SET face TO img_to_array(face)

                SET face TO preprocess_INPUT(face)



                # add the face and bounding boxes to their respective

                # lists

                faces.append(face)

                locs.append((startX, startY, endX, endY))



        # only make a predictions IF at least one face was detected

        IF len(faces) > 0:

            # FOR faster inference we'll make batch predictions on *all*

            # faces at the same time rather than one-by-one predictions

            # IN the above `for` loop

            SET faces TO np.array(faces, dtype="float32")

            SET preds TO maskNet.predict(faces, batch_size=32)



        # RETURN a 2-tuple of the face locations and their corresponding

        # locations

        RETURN (locs, preds)





    DEFINE FUNCTION update_recognized_text(self):

        self.question_label.configure(text=recognizer.question_text)

        self.answer_label.configure(text=recognizer.answer_text)

        SET self.start_face_detection TO recognizer.start_face_detection

    

    # Function FOR video streaming

    DEFINE FUNCTION video_stream(self):

        self.update_recognized_text()

        global counter_no_mask

        global counter



        SET frame TO vs.read()

        SET frame TO imutils.resize(frame, width=400)



        IF (self.start_face_detection EQUALS True):

            # detect faces IN the frame and determine IF they are wearing a

            # face mask or not

            SET (locs, preds) TO self.detect_and_predict_mask(frame, faceNet, maskNet)



            # loop over the detected face locations and their corresponding

            # locations

            FOR (box, pred) IN zip(locs, preds):

                # unpack the bounding box and predictions

                SET (startX, startY, endX, endY) TO box

                SET (mask, withoutMask) TO pred



                # determine the DEFINE CLASS label and color we'll use to draw

                # the bounding box and text

                SET label TO "Mask" IF mask > withoutMask else "No Mask"

                IF label EQUALS 'Mask':

                    counter+=1

                ELSE:

                    counter_no_mask+=1

                IF counter_no_mask EQUALS 50:

                    playsound("warning.mp3")

                    counter_no_mask=0



                IF counter== 40:

                    SET counter_no_mask TO 0

                    SET counter TO 0

                    playsound("welcome.mp3")

                    SET recognizer.start_face_detection TO False

                    recognizer.delay=1

                    # time.sleep(3)

                

                SET color TO (0, 255, 0) IF label EQUALS "Mask" else (0, 0, 255)



                # include the probability IN the label

                SET label TO "{}: {:.2f}%".format(label, max(mask, withoutMask) * 100)



                # display the label and bounding box rectangle on the output

                # frame

            

                cv2.putText(frame, label, (startX, startY - 10),

                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)

                cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)

        SET self.cv2image TO cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)

        SET self.img TO Img.fromarray(self.cv2image)

        SET self.imgtk TO ImageTk.PhotoImage(image=self.img)

        SET self.lmain.imgtk TO self.imgtk

        self.lmain.configure(image=self.imgtk)

        self.lmain.after(1, self.video_stream) 

    



SET root TO tki.Tk()

SET app TO App(root)

root.mainloop()
